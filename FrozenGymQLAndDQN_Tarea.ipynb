{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Aprendizaje por refuerzos** - FrozenLake y LunarLander (Gymnasium)\n",
        "\n",
        "## Tarea: Implementar Agentes Q-Learning y DQN\n",
        "\n",
        "### Objetivos:\n",
        "1. Implementar el algoritmo Q-Learning\n",
        "2. Implementar el algoritmo DQN\n",
        "3. Entrenar y evaluar ambos agentes\n",
        "4. Comparar el rendimiento de ambos enfoques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar paquetes requeridos\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "%pip install swig matplotlib gymnasium torch pygame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar las bibliotecas\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pygame\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from collections import deque, namedtuple\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La siguiente celda permite ejecutar un juego de Frozen Lake *determinista* para jugar con el teclado.\n",
        "\n",
        "Utilize las teclas de dirección (flechas) o asdw para comandar al agente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def jugar_frozen_lake(env):\n",
        "    env.reset()\n",
        "    \n",
        "    print(\"Controles:\")\n",
        "    print(\"W - Arriba\")\n",
        "    print(\"S - Abajo\") \n",
        "    print(\"A - Izquierda\")\n",
        "    print(\"D - Derecha\")\n",
        "    print(\"Q - Salir\")\n",
        "    print(\"Presione cualquier tecla para empezar...\")\n",
        "    \n",
        "    pygame.init()\n",
        "    pygame.display.set_caption(\"FrozenLake - Juego Interactivo\")\n",
        "    \n",
        "    clock = pygame.time.Clock()\n",
        "    ejecutando = True\n",
        "    \n",
        "    while ejecutando:\n",
        "        for event in pygame.event.get():\n",
        "            if event.type == pygame.QUIT:\n",
        "                ejecutando = False\n",
        "            elif event.type == pygame.KEYDOWN:\n",
        "                if event.key == pygame.K_q or event.key == pygame.K_ESCAPE:\n",
        "                    ejecutando = False\n",
        "                elif event.key == pygame.K_w or event.key == pygame.K_UP:\n",
        "                    accion = 3  # Arriba\n",
        "                elif event.key == pygame.K_s or event.key == pygame.K_DOWN:\n",
        "                    accion = 1  # Abajo\n",
        "                elif event.key == pygame.K_a or event.key == pygame.K_LEFT:\n",
        "                    accion = 0  # Izquierda\n",
        "                elif event.key == pygame.K_d or event.key == pygame.K_RIGHT:\n",
        "                    accion = 2  # Derecha\n",
        "                else:\n",
        "                    continue\n",
        "                \n",
        "                observacion, recompensa, terminado, truncado, info = env.step(accion)\n",
        "                print(f\"Acción: {accion}, Recompensa: {recompensa}, Terminado: {terminado}\")\n",
        "                \n",
        "                if terminado or truncado:\n",
        "                    print(f\"¡Episodio terminado! Recompensa final: {recompensa}\")\n",
        "                    pygame.time.wait(500)\n",
        "                    env.reset()\n",
        "        \n",
        "        clock.tick(60)\n",
        "    \n",
        "    pygame.quit()\n",
        "    env.close()\n",
        "\n",
        "env = gym.make('FrozenLake-v1', render_mode='human', is_slippery=False)\n",
        "# Descomente la línea de abajo para jugar interactivamente\n",
        "# jugar_frozen_lake(env)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La siguiente celda permite jugar al juego no determinista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make('FrozenLake-v1', render_mode='human', is_slippery=True)\n",
        "# Descomente la línea de abajo para jugar interactivamente\n",
        "jugar_frozen_lake(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La siguiente clase define la interfaz de los agentes que utilizaremos para jugar al Frozen Lake.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class Agente(ABC):\n",
        "    \n",
        "    @abstractmethod\n",
        "    def elegir_accion(self, estado):\n",
        "        \"\"\"Elige una acción dada una observación.\"\"\"\n",
        "        pass\n",
        "    \n",
        "    @abstractmethod\n",
        "    def aprender(self, estado, accion, recompensa, siguiente_estado, terminado):\n",
        "        \"\"\"Aprende de la experiencia.\"\"\"\n",
        "        pass\n",
        "\n",
        "class AgenteAleatorio(Agente):\n",
        "    \"\"\"Agente aleatorio que elige acciones al azar.\"\"\"\n",
        "    \n",
        "    def __init__(self, espacio_acciones):\n",
        "        # Se guarda el espacio de acciones para poder elegir acciones al azar\n",
        "        self.espacio_acciones = espacio_acciones\n",
        "    \n",
        "    def elegir_accion(self, estado):\n",
        "        return self.espacio_acciones.sample()\n",
        "    \n",
        "    def aprender(self, estado, accion, recompensa, siguiente_estado, terminado):\n",
        "        pass  # El agente aleatorio no aprende\n",
        "\n",
        "# Probar el AgenteAleatorio\n",
        "env = gym.make('FrozenLake-v1')\n",
        "agente_aleatorio = AgenteAleatorio(env.action_space)\n",
        "estado, _ = env.reset()\n",
        "accion = agente_aleatorio.elegir_accion(estado)\n",
        "print(f\"✓ AgenteAleatorio creado y probado. Acción: {accion}\")\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La siguiente celda define una función para evaluar el desempeño de un agente dado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función de Evaluación de Agentes\n",
        "def evaluar_agente(agente, env, num_episodios=1000):\n",
        "    \"\"\"\n",
        "    Evalúa el rendimiento de un agente a lo largo de múltiples episodios.\n",
        "    \n",
        "    Args:\n",
        "        agente: El agente a evaluar\n",
        "        env: El entorno\n",
        "        num_episodios: Número de episodios a ejecutar\n",
        "    \n",
        "    Returns:\n",
        "        dict: Resultados de la evaluación\n",
        "    \"\"\"\n",
        "    recompensas_totales = []\n",
        "    victorias = 0\n",
        "    \n",
        "    for episodio in range(num_episodios):\n",
        "        estado, _ = env.reset()\n",
        "        recompensa_total = 0\n",
        "        \n",
        "        while True:\n",
        "            accion = agente.elegir_accion(estado)\n",
        "            estado, recompensa, terminado, truncado, _ = env.step(accion)\n",
        "            recompensa_total += recompensa\n",
        "            \n",
        "            if terminado or truncado:\n",
        "                break\n",
        "        \n",
        "        recompensas_totales.append(recompensa_total)\n",
        "        if recompensa_total > 0:\n",
        "            victorias += 1\n",
        "    \n",
        "    return {\n",
        "        'recompensas_totales': recompensas_totales,\n",
        "        'victorias': victorias,\n",
        "        'tasa_victorias': victorias / num_episodios,\n",
        "        'recompensa_promedio': np.mean(recompensas_totales),\n",
        "        'desv_estandar': np.std(recompensas_totales)\n",
        "    }\n",
        "\n",
        "def imprimir_resultados_evaluacion(resultados, nombre_agente):\n",
        "    \"\"\"Imprime los resultados de evaluación de forma formateada.\"\"\"\n",
        "    print(f\"\\n{nombre_agente} - Resultados de Evaluación:\")\n",
        "    print(f\"Tasa de Victorias: {resultados['tasa_victorias']:.1%}\")\n",
        "    print(f\"Recompensa Promedio: {resultados['recompensa_promedio']:.3f}\")\n",
        "    print(f\"Desviación Estándar: {resultados['desv_estandar']:.3f}\")\n",
        "    print(f\"Total de Victorias: {resultados['victorias']}\")\n",
        "\n",
        "# Probar función de evaluación\n",
        "env = gym.make('FrozenLake-v1')\n",
        "agente_aleatorio = AgenteAleatorio(env.action_space)\n",
        "resultados = evaluar_agente(agente_aleatorio, env, num_episodios=100)\n",
        "imprimir_resultados_evaluacion(resultados, \"Agente Aleatorio\")\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La siguiente celda define una función para entrenar un agente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función de Entrenamiento de Agentes\n",
        "def entrenar_agente(agente, env, num_episodios=1000, max_pasos=100, verbose=True):\n",
        "    \"\"\"\n",
        "    Entrena un agente en el entorno.\n",
        "    \n",
        "    Args:\n",
        "        agente: El agente a entrenar\n",
        "        env: El entorno\n",
        "        num_episodios: Número de episodios de entrenamiento\n",
        "        max_pasos: Máximo de pasos por episodio\n",
        "        verbose: Si imprimir el progreso\n",
        "    \n",
        "    Returns:\n",
        "        list: Recompensas de episodios\n",
        "    \"\"\"\n",
        "    recompensas_episodios = []\n",
        "    longitudes_episodios = []\n",
        "    num_episodios_10 = int(num_episodios / 10)\n",
        "    \n",
        "    for episodio in range(num_episodios):\n",
        "        estado, _ = env.reset()\n",
        "        recompensa_total = 0\n",
        "        pasos = 0\n",
        "        \n",
        "        for paso in range(max_pasos):\n",
        "            accion = agente.elegir_accion(estado)\n",
        "            siguiente_estado, recompensa, terminado, truncado, _ = env.step(accion)\n",
        "            \n",
        "            agente.aprender(estado, accion, recompensa, siguiente_estado, terminado or truncado)\n",
        "            \n",
        "            estado = siguiente_estado\n",
        "            recompensa_total += recompensa\n",
        "            pasos += 1\n",
        "            \n",
        "            if terminado or truncado:\n",
        "                break\n",
        "        \n",
        "        recompensas_episodios.append(recompensa_total)\n",
        "        longitudes_episodios.append(pasos)\n",
        "        \n",
        "        if verbose and (episodio + 1) % num_episodios_10 == 0:\n",
        "            recompensa_promedio = np.mean(recompensas_episodios[-num_episodios_10:])\n",
        "            longitud_promedio = np.mean(longitudes_episodios[-num_episodios_10:])\n",
        "            print(f\"Episodio {episodio + 1}: Recompensa Promedio = {recompensa_promedio:.3f}, Longitud Promedio = {longitud_promedio:.1f}\")\n",
        "    \n",
        "    return recompensas_episodios, longitudes_episodios\n",
        "\n",
        "print(\"✓ Funciones de entrenamiento definidas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La siguiente celda define el agente de Q-Learning a implementar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implementar Agente Q-Learning\n",
        "class AgenteQLearning(Agente):\n",
        "    \"\"\"Agente que usa el algoritmo Q-Learning.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def elegir_accion(self, estado):\n",
        "        \"\"\"Elige una acción usando política epsilon-greedy.\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def aprender(self, estado, accion, recompensa, siguiente_estado, terminado):\n",
        "        \"\"\"Actualiza la tabla Q usando la ecuación de Bellman.\"\"\"\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqui deberán incluir código para entrenar y evaluar el agente de Q-Learning implementado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La siguiente celda define el agente DQN a implementar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class DQN(nn.Module):\n",
        "    \"\"\"Clase auxiliar que implementa una Red Q Profunda con una capa oculta.\"\"\"\n",
        "    \n",
        "    def __init__(self, tamano_entrada, tamano_oculto, tamano_salida):\n",
        "        super(DQN, self).__init__()\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "class AgenteDQN(Agente):\n",
        "    \"\"\"Agente de Red Q Profunda.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def elegir_accion(self, estado):\n",
        "        \"\"\"Elige acción usando política epsilon-greedy.\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def aprender(self, estado, accion, recompensa, siguiente_estado, terminado):\n",
        "        pass\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aqui deberán incluir código para entrenar y evaluar el agente de DQN \n",
        "implementado.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
